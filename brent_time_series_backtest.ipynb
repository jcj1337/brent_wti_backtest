{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e6EsiNjvFj8"
      },
      "source": [
        "Backtest on commodities (Brent crude oil). We will use daily data.\n",
        "\n",
        "More of a conceptual project than anything else, we'll ignore slippage and annoying fees, also assuming perfect liquidity, and so on and so forth.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "sNzrdqFtvHqI",
        "outputId": "33b9fe51-7378-4040-f64f-b7cd6f66100d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-28508781-8763-4076-a481-089c41fc4fda\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-28508781-8763-4076-a481-089c41fc4fda\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving brent-daily.csv to brent-daily (1).csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-416e700a-2aa6-4537-a060-428533f9f710\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-416e700a-2aa6-4537-a060-428533f9f710\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving wti-daily.csv to wti-daily (1).csv\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "uploaded2 = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YJcPz6ccvpy0",
        "outputId": "ddd6e8e5-335e-4035-c6ff-577a5e35585f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9806,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 9806,\n        \"samples\": [\n          \"2013-07-25\",\n          \"2025-09-30\",\n          \"2004-05-28\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.570101185751824,\n        \"min\": 9.1,\n        \"max\": 143.95,\n        \"num_unique_values\": 5437,\n        \"samples\": [\n          110.76,\n          63.83,\n          63.65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a4285e25-b55a-4c22-a1b4-c916513bae70\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1987-05-20</td>\n",
              "      <td>18.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1987-05-21</td>\n",
              "      <td>18.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1987-05-22</td>\n",
              "      <td>18.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1987-05-25</td>\n",
              "      <td>18.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1987-05-26</td>\n",
              "      <td>18.63</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4285e25-b55a-4c22-a1b4-c916513bae70')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a4285e25-b55a-4c22-a1b4-c916513bae70 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a4285e25-b55a-4c22-a1b4-c916513bae70');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         Date  Price\n",
              "0  1987-05-20  18.63\n",
              "1  1987-05-21  18.45\n",
              "2  1987-05-22  18.55\n",
              "3  1987-05-25  18.60\n",
              "4  1987-05-26  18.63"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"brent-daily.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHRHUWtl1-_1"
      },
      "source": [
        "This dataset is from 1987-present. I think it would be unwise to use data this far back as regimes change over time. In other words, we probably have too much data and we may encounter problems like the Simpson's paradox (E.g. maybe a strategy is great from 1987-1999 but terrible after that, yet averaged together this effect is hidden).\n",
        "\n",
        "\n",
        "Of course we still need \"enough\" data though, so 2 decades worth is probably enough, although pretty arbitrary (but we need to start somewhere) let's just cutoff everything before 2005."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oJK_uQth6u_q"
      },
      "outputs": [],
      "source": [
        "df = df.copy()\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "df = df[df[\"Date\"] >= \"2005-01-01\"]\n",
        "df = df.sort_values(\"Date\").drop_duplicates(\"Date\")\n",
        "df[\"r\"] = df[\"Price\"].pct_change()\n",
        "df = df.set_index(\"Date\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Ctp44RaWCsP0"
      },
      "outputs": [],
      "source": [
        "# replace NaN with 0\n",
        "df[\"r\"] = df[\"r\"].fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0MJ5vXK4dMW"
      },
      "source": [
        "Let's first define our **strategy** with buy and hold as our baseline:\n",
        "\n",
        "**1.** **First** signal quite simple, will just be binary and 1 if our price is above the *moving average* of say, 50 days. I don't want to COMPLETELY arbitrarily pick a deadband so we will *quantitatively* calculate one by using a cost-based system.\n",
        "\n",
        "*   Input a list of possible deltas (deadband values)\n",
        "*   Evaluate performance through a Sharpe ratio on train\n",
        "*   Pick the delta from the list that maximizes the ratio while slightly penalizing excessive turnover\n",
        "\n",
        "I feel this system is pretty intuitive (so good for our case) although I'm sure there's a smarter way to go about things. I think 50 days is fair for a commodity (longer typically better?).\n",
        "\n",
        "\\\n",
        "**2.** **Second** will be mean reversion, i.e. z-score vs rolling mean.\n",
        "\n",
        "**3.** **Third** Let's define our *position* as long/flat/short = -1/0/1. In simpler terms either we're shorting, completely out, or in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YA3hyg8WE1ym"
      },
      "outputs": [],
      "source": [
        "# helpers\n",
        "def make_trend_positions(df, ma_window=50, delta=0.005):\n",
        "    \"\"\"\n",
        "    Creates trend positions {-1,0,1} from price and moving average with a deadband.\n",
        "    Returns a Series pos_trend_raw indexed by date.\n",
        "    \"\"\"\n",
        "    ma = df[\"Price\"].rolling(ma_window).mean()\n",
        "    trend_score = df[\"Price\"] / ma - 1\n",
        "\n",
        "    pos = np.select(\n",
        "        [trend_score > delta, trend_score < -delta],\n",
        "        [1, -1],\n",
        "        default=0\n",
        "    )\n",
        "    return pd.Series(pos, index=df.index, name=\"pos_trend_raw\")\n",
        "\n",
        "\n",
        "def backtest_from_pos_raw(df, pos_raw, cost_bps=10):\n",
        "    \"\"\"\n",
        "    Takes pos_trend_raw and performs a backtest on it\n",
        "    \"\"\"\n",
        "    out = df[[\"Price\", \"r\"]].copy()\n",
        "    out[\"pos_raw\"] = pos_raw\n",
        "\n",
        "    # Shift 1 day back to avoid lookahead\n",
        "    out[\"pos\"] = out[\"pos_raw\"].shift(1).fillna(0)\n",
        "\n",
        "    out[\"turnover\"] = (out[\"pos\"] - out[\"pos\"].shift(1)).abs().fillna(0)\n",
        "    c = cost_bps / 10000.0\n",
        "    out[\"cost\"] = c * out[\"turnover\"]\n",
        "\n",
        "    out[\"strat_r\"] = out[\"pos\"] * out[\"r\"].fillna(0) - out[\"cost\"]\n",
        "    out[\"equity\"] = (1 + out[\"strat_r\"]).cumprod()\n",
        "    return out\n",
        "\n",
        "\n",
        "def sharpe_ann(strat_r, trading_days=252):\n",
        "    \"\"\"\n",
        "    Annual sharp calculation\n",
        "    \"\"\"\n",
        "    strat_r = strat_r.dropna()\n",
        "    if len(strat_r) < 50:\n",
        "        return np.nan\n",
        "    mu = strat_r.mean() * trading_days\n",
        "    vol = strat_r.std(ddof=0) * np.sqrt(trading_days)\n",
        "    return np.nan if vol == 0 else mu / vol\n",
        "\n",
        "\n",
        "def choose_deadband_delta(\n",
        "    df,\n",
        "    train_start=None,\n",
        "    train_end=None,\n",
        "    ma_window=50,\n",
        "    delta_grid=None,\n",
        "    cost_bps=10,\n",
        "    lambda_reg=0.001,\n",
        "):\n",
        "    \"\"\"\n",
        "    Picks a delta from an input grid by maximizing annualized Sharpe while penalizing turnover.\n",
        "    \"\"\"\n",
        "\n",
        "    # Default\n",
        "    if delta_grid is None:\n",
        "        delta_grid = [0.0, 0.0025, 0.005, 0.01, 0.02]\n",
        "\n",
        "    dtrain = df.copy()\n",
        "    start = pd.to_datetime(train_start)\n",
        "    end   = pd.to_datetime(train_end)\n",
        "    dtrain = dtrain.loc[start:end]\n",
        "\n",
        "    best = {\"delta\": None, \"score\": -np.inf, \"sharpe\": None, \"turnover_per_year\": None}\n",
        "    rows = []\n",
        "\n",
        "    for delta in delta_grid:\n",
        "        pos_raw = make_trend_positions(dtrain, ma_window=ma_window, delta=delta)\n",
        "        bt = backtest_from_pos_raw(dtrain, pos_raw, cost_bps=cost_bps)\n",
        "\n",
        "        s = sharpe_ann(bt[\"strat_r\"])\n",
        "        turnover_per_year = bt[\"turnover\"].mean() * 252\n",
        "\n",
        "        # Objective\n",
        "        score = s - lambda_reg * turnover_per_year\n",
        "\n",
        "        rows.append((delta, s, turnover_per_year, score))\n",
        "\n",
        "        if np.isfinite(score) and score > best[\"score\"]:\n",
        "            best = {\n",
        "                \"delta\": float(delta),\n",
        "                \"score\": float(score),\n",
        "                \"sharpe\": float(s) if np.isfinite(s) else np.nan,\n",
        "                \"turnover_per_year\": float(turnover_per_year),\n",
        "            }\n",
        "\n",
        "    results = pd.DataFrame(rows, columns=[\"delta\", \"train_sharpe\", \"turnover_per_year\", \"score\"])\n",
        "    results = results.sort_values(\"score\", ascending=False)\n",
        "\n",
        "    return best, results\n",
        "\n",
        "def make_mr_positions(df, z_window=20, a=1.0):\n",
        "    \"\"\"\n",
        "    Mean reversion positions {-1,0,1}. Uses z-score of log price vs rolling mean/std.\n",
        "    \"\"\"\n",
        "    logP = np.log(df[\"Price\"])\n",
        "    mu = logP.rolling(z_window).mean()\n",
        "    sd = logP.rolling(z_window).std(ddof=0)\n",
        "    z = (logP - mu) / sd\n",
        "\n",
        "    pos = np.select(\n",
        "        [z < -a, z > a],\n",
        "        [-1, 1],\n",
        "        default=0\n",
        "    )\n",
        "    return pd.Series(pos, index=df.index, name=\"pos_mr_raw\")\n",
        "\n",
        "def choose_mr_threshold(\n",
        "    df,\n",
        "    train_start=None,\n",
        "    train_end=None,\n",
        "    z_window=10,\n",
        "    a_grid=None,\n",
        "    cost_bps=10,\n",
        "    lambda_turnover=0.0001\n",
        "):\n",
        "    \"\"\"\n",
        "    Similar logic to choose_deadband_delta, but for mean reversion.\n",
        "    I.e. picks delta from input grid by maximizing annualized Sharpe while penalizing turnover.\n",
        "    \"\"\"\n",
        "    if a_grid is None:\n",
        "        a_grid = [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]\n",
        "\n",
        "    dtrain = df.copy()\n",
        "    start = pd.to_datetime(train_start) if train_start is not None else dtrain.index.min()\n",
        "    end   = pd.to_datetime(train_end)   if train_end is not None else dtrain.index.max()\n",
        "    dtrain = dtrain.loc[start:end]\n",
        "\n",
        "    best = {\"a\": None, \"score\": -np.inf, \"sharpe\": None, \"turnover_per_year\": None}\n",
        "    rows = []\n",
        "\n",
        "    for a in a_grid:\n",
        "        pos_raw = make_mr_positions(dtrain, z_window=z_window, a=a)\n",
        "        bt = backtest_from_pos_raw(dtrain, pos_raw, cost_bps=cost_bps)\n",
        "\n",
        "        s = sharpe_ann(bt[\"strat_r\"])\n",
        "        turnover_per_year = bt[\"turnover\"].mean() * 252\n",
        "        score = s - lambda_turnover * turnover_per_year\n",
        "\n",
        "        rows.append((a, s, turnover_per_year, score))\n",
        "\n",
        "        if np.isfinite(score) and score > best[\"score\"]:\n",
        "            best = {\n",
        "                \"a\": float(a),\n",
        "                \"score\": float(score),\n",
        "                \"sharpe\": float(s) if np.isfinite(s) else np.nan,\n",
        "                \"turnover_per_year\": float(turnover_per_year)\n",
        "            }\n",
        "\n",
        "    results = pd.DataFrame(rows, columns=[\"a\", \"train_sharpe\", \"turnover_per_year\", \"score\"]).sort_values(\"score\", ascending=False)\n",
        "    return best, results\n",
        "\n",
        "def metrics(bt, trading_days=252):\n",
        "    \"\"\"\n",
        "    get relevant metrics from a backtest\n",
        "    \"\"\"\n",
        "    r = bt[\"strat_r\"].dropna()\n",
        "    if len(r) < 2:\n",
        "        return {}\n",
        "\n",
        "    total = bt[\"equity\"].iloc[-1] - 1\n",
        "    ann_ret = (bt[\"equity\"].iloc[-1]) ** (trading_days / len(r)) - 1\n",
        "    ann_vol = r.std() * np.sqrt(trading_days)\n",
        "    sharpe = np.nan if ann_vol == 0 else ann_ret / ann_vol\n",
        "\n",
        "    # Max drawdown\n",
        "    peak = bt[\"equity\"].cummax()\n",
        "    dd = bt[\"equity\"] / peak - 1\n",
        "    max_dd = dd.min()\n",
        "\n",
        "    avg_turnover = bt[\"turnover\"].mean()\n",
        "    trades_per_year = avg_turnover * trading_days\n",
        "\n",
        "    return {\n",
        "        \"Total Return\": total,\n",
        "        \"Ann Return\": ann_ret,\n",
        "        \"Ann Vol\": ann_vol,\n",
        "        \"Sharpe\": sharpe,\n",
        "        \"Max Drawdown\": max_dd,\n",
        "        \"Avg Daily Turnover\": avg_turnover,\n",
        "        \"Turnover/yr (proxy)\": trades_per_year\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8F396JFDfUs",
        "outputId": "f5032a13-8d88-4b85-c061-746712934cff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Delta chosen: {'delta': 0.01, 'score': 0.23420924590239867, 'sharpe': 0.2677039688575438, 'turnover_per_year': 33.49472295514512}\n",
            "MR chosen: {'a': 2.0, 'score': 0.5613274921546707, 'sharpe': 0.5642697085135098, 'turnover_per_year': 29.4221635883905}\n"
          ]
        }
      ],
      "source": [
        "# split\n",
        "train_start, train_end = \"2005-01-04\", \"2016-12-31\"\n",
        "test_start,  test_end  = \"2017-01-01\", \"2025-12-31\"\n",
        "\n",
        "# calls, note some of these numbers are arbitrary for our purposes, e.g. we just randomly set cost to 10 bps and max turnover to once a day\n",
        "\n",
        "# signal 1\n",
        "best_ma, delta_table = choose_deadband_delta(\n",
        "    df,\n",
        "    train_start=train_start,\n",
        "    train_end=train_end,\n",
        ")\n",
        "delta_ma = best_ma[\"delta\"] if best_ma[\"delta\"] is not None else 0.005\n",
        "print(\"Delta chosen:\", best_ma)\n",
        "# signal 2\n",
        "best_mr, mr_table = choose_mr_threshold(\n",
        "    df,\n",
        "    train_start=train_start,\n",
        "    train_end=train_end,\n",
        ")\n",
        "delta_mr = best_mr[\"a\"] if best_mr[\"a\"] is not None else 1.0\n",
        "print(\"MR chosen:\", best_mr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJBRkIZiR4ZW"
      },
      "source": [
        "It is interesting to note the Sharpe ratio and score is always negative for the mean reversion case UNDER THE REGULAR mean reversion signal (e.g. z < -a = 1; z > a = -1). However, if we invert the signal we find that the Sharpe and scores turn positive; this is intriguing for as it essentially implies that this signal (\"the price is noticeably above/below its average\") acts as a **regime** signal rather than a mean reversion one.\n",
        "\n",
        "TLDR: For the case of Brent we see that trends/regimes are more likely to follow when we observe outlier values rather than mean reversion. So truthfully we should just re-label our second function to something more honest, although I guess we wouldn't know this if we didn't first test the mean reversion case.\n",
        "\n",
        "**Expectations** Let's make this even more concrete. We can calculate the average next-day return for two cases, one when z > a, and one when z < -a (high vs low)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhgYLJLhWwWO",
        "outputId": "5cdecee9-e265-4473-caa8-bcda08c817fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counts: 303 343 4657\n",
            "E[r_{t+1} | z_t > a]   = 17.39217023766222\n",
            "E[r_{t+1} | z_t < -a]  = -7.681004202530294\n",
            "E[r_{t+1} | |z_t|<=a]  = 0.2641685170813399\n"
          ]
        }
      ],
      "source": [
        "# expectations\n",
        "z_window = 20\n",
        "a = 2.0\n",
        "\n",
        "df = df.copy()\n",
        "df[\"logP\"] = np.log(df[\"Price\"])\n",
        "df[\"r_next\"] = df[\"logP\"].diff().shift(-1)   # r_{t+1} aligned to time t\n",
        "\n",
        "mu = df[\"logP\"].rolling(z_window).mean()\n",
        "sd = df[\"logP\"].rolling(z_window).std(ddof=0)\n",
        "df[\"z\"] = (df[\"logP\"] - mu) / sd\n",
        "high = df[\"z\"] > a\n",
        "low  = df[\"z\"] < -a\n",
        "mid  = (df[\"z\"] >= -a) & (df[\"z\"] <= a)\n",
        "\n",
        "E_high = df.loc[high, \"r_next\"].mean() * 10000\n",
        "E_low  = df.loc[low,  \"r_next\"].mean()* 10000\n",
        "E_mid  = df.loc[mid,  \"r_next\"].mean()* 10000\n",
        "\n",
        "print(\"Counts:\", high.sum(), low.sum(), mid.sum())\n",
        "print(\"E[r_{t+1} | z_t > a]   =\", E_high)\n",
        "print(\"E[r_{t+1} | z_t < -a]  =\", E_low)\n",
        "print(\"E[r_{t+1} | |z_t|<=a]  =\", E_mid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n1hNCx7XqNK"
      },
      "source": [
        "We can see that When z is high, an average of 17.4 bps/day and when low an avergae of -7.7 bps/day. Also worth noting is the \"mid\" group is positive, indicating a general upward trend. This all supports what we articulated in english, except in a quantitative way ðŸ˜Š\n",
        "\n",
        "\\\n",
        "Let's get back on track with the actual backtester though."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y77H-3lZsux",
        "outputId": "1519fee8-4e05-4a9d-c729-ff470c92352d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Total Return': np.float64(-0.7431788490604168), 'Ann Return': np.float64(-0.13933446884009892), 'Ann Vol': np.float64(0.46858894676826346), 'Sharpe': np.float64(-0.2973490301063494), 'Max Drawdown': -0.9161334221372163, 'Avg Daily Turnover': np.float64(0.13447218572054315), 'Turnover/yr (proxy)': np.float64(33.88699080157687)}\n",
            "{'Total Return': np.float64(-0.710225508116252), 'Ann Return': np.float64(-0.12778887848158005), 'Ann Vol': np.float64(0.22714251210657263), 'Sharpe': np.float64(-0.5625934013691941), 'Max Drawdown': -0.7618354101589179, 'Avg Daily Turnover': np.float64(0.12352168199737187), 'Turnover/yr (proxy)': np.float64(31.127463863337713)}\n",
            "Worst 10 days:\n",
            "             pos         r   strat_r\n",
            "Date                               \n",
            "2020-04-22 -1.0  0.509868 -0.509868\n",
            "2020-04-02 -1.0  0.352037 -0.352037\n",
            "2020-05-05 -1.0  0.248039 -0.248039\n",
            "2020-04-03 -1.0  0.202075 -0.202075\n",
            "2020-04-29 -1.0  0.144872 -0.144872\n",
            "2020-04-08 -1.0  0.141176 -0.141176\n",
            "2022-03-09  1.0 -0.124643 -0.124643\n",
            "2020-05-04 -1.0  0.103299 -0.103299\n",
            "2020-04-23 -1.0  0.093682 -0.093682\n",
            "2022-07-05  1.0 -0.092857 -0.092857\n",
            "\n",
            "Best 10 days:\n",
            "             pos         r   strat_r\n",
            "Date                               \n",
            "2020-04-21 -1.0 -0.474654  0.474654\n",
            "2020-03-31 -1.0 -0.226159  0.226159\n",
            "2020-03-09 -1.0 -0.225219  0.225219\n",
            "2020-04-09 -1.0 -0.197859  0.197859\n",
            "2020-03-18 -1.0 -0.185198  0.185198\n",
            "2020-03-30 -1.0 -0.142921  0.142921\n",
            "2020-03-16 -1.0 -0.132403  0.132403\n",
            "2020-04-20 -1.0 -0.121013  0.121013\n",
            "2020-03-06 -1.0 -0.110938  0.110938\n",
            "2020-03-12 -1.0 -0.099565  0.099565\n",
            "\n",
            "Largest abs returns days:\n",
            "             Price         r\n",
            "Date                       \n",
            "2020-04-22  13.77  0.509868\n",
            "2020-04-21   9.12 -0.474654\n",
            "2020-04-02  20.24  0.352037\n",
            "2020-05-05  25.46  0.248039\n",
            "2020-03-31  14.85 -0.226159\n",
            "2020-03-09  35.33 -0.225219\n",
            "2020-04-03  24.33  0.202075\n",
            "2020-04-09  20.23 -0.197859\n",
            "2020-03-18  22.79 -0.185198\n",
            "2020-04-29  17.86  0.144872\n"
          ]
        }
      ],
      "source": [
        "df_test = df.loc[\"2017-01-01\":\"2025-12-31\"].copy()\n",
        "\n",
        "# recompute signals/positions on df_test\n",
        "df_test[\"pos_trend_raw\"] = make_trend_positions(df_test, ma_window=50, delta=delta_ma)\n",
        "df_test[\"pos_mr_raw\"]    = make_mr_positions(df_test, z_window=20, a=delta_mr)\n",
        "\n",
        "bt_trend_test = backtest_from_pos_raw(df_test, df_test[\"pos_trend_raw\"])\n",
        "bt_mr_test    = backtest_from_pos_raw(df_test, df_test[\"pos_mr_raw\"])\n",
        "\n",
        "print(metrics(bt_trend_test))\n",
        "print(metrics(bt_mr_test))\n",
        "\n",
        "worst = bt_trend_test.nsmallest(10, \"strat_r\")[[\"pos\", \"r\", \"strat_r\"]]\n",
        "best  = bt_trend_test.nlargest(10, \"strat_r\")[[\"pos\", \"r\", \"strat_r\"]]\n",
        "\n",
        "print(\"Worst 10 days:\\n\", worst)\n",
        "print(\"\\nBest 10 days:\\n\", best)\n",
        "\n",
        "# Also check worst underlying returns days\n",
        "print(\"\\nLargest abs returns days:\\n\", df_test.loc[df_test[\"r\"].abs().sort_values(ascending=False).head(10).index, [\"Price\",\"r\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKNtxvVafcKk"
      },
      "source": [
        "Our strategy is pretty terrible as it is set-up now. We can see average returns of  around -70% each. Upon further analysis, we can see that during a Black Swan event (2020 march-ish) the strategy is exploited and exploited badly, suffering great losses.\n",
        "\n",
        "My most immediate instinct is to reduce volatility. Let's introduce a function that scales our position down when volatility spikes.\n",
        "\n",
        "Something like:\n",
        "\n",
        "$$\n",
        "\\text{pos}_t = \\text{pos}_t \\cdot \\min\\left(1,\\frac{\\sigma_{\\text{target}}}{\\sigma_t}\\right)\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3watGMPUiDar"
      },
      "outputs": [],
      "source": [
        "# updated function\n",
        "def backtest_from_pos_raw_v2(df, pos_raw, cost_bps=10, vol_window=10, target_vol_ann=0.10):\n",
        "    \"\"\"\n",
        "    Backtest with volatility targeting (scales position magnitude)\n",
        "\n",
        "    target_vol_ann: annualized vol target (e.g., 0.20 = 20%/yr)\n",
        "    \"\"\"\n",
        "    out = df[[\"Price\", \"r\"]].copy()\n",
        "    out[\"r\"] = out[\"r\"].fillna(0)\n",
        "    out[\"pos_raw\"] = pos_raw\n",
        "\n",
        "    # Lag to avoid lookahead\n",
        "    out[\"pos\"] = out[\"pos_raw\"].shift(1).fillna(0)\n",
        "\n",
        "    # rolling daily vol\n",
        "    out[\"vol_d\"] = out[\"r\"].rolling(vol_window).std(ddof=0)\n",
        "\n",
        "    # target daily vol\n",
        "    target_vol_d = target_vol_ann / np.sqrt(252)\n",
        "\n",
        "    # scaling factor\n",
        "    out[\"scale\"] = (target_vol_d / out[\"vol_d\"]).clip(upper=1.0)\n",
        "    out[\"scale\"] = out[\"scale\"].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "    # scaled position (continuous)\n",
        "    out[\"pos_scaled\"] = out[\"pos\"] * out[\"scale\"]\n",
        "\n",
        "    # Turnover + costs should be based on the position you actually hold\n",
        "    out[\"turnover\"] = (out[\"pos_scaled\"] - out[\"pos_scaled\"].shift(1)).abs().fillna(0)\n",
        "    c = cost_bps / 10000.0\n",
        "    out[\"cost\"] = c * out[\"turnover\"]\n",
        "\n",
        "    out[\"strat_r\"] = out[\"pos_scaled\"] * out[\"r\"] - out[\"cost\"]\n",
        "    out[\"equity\"] = (1 + out[\"strat_r\"]).cumprod()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKCU9xWQiLN2",
        "outputId": "e702ded0-91e8-4eb2-b54f-e9495f5aa955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Brent buy and hold return: 0.11626637554585617\n",
            "{'Total Return': np.float64(0.6661979730065155), 'Ann Return': np.float64(0.057972602421368036), 'Ann Vol': np.float64(0.1011760232894703), 'Sharpe': np.float64(0.5729875570964591), 'Max Drawdown': -0.20683890286106366, 'Avg Daily Turnover': np.float64(0.07450687721350331), 'Turnover/yr (proxy)': np.float64(18.775733057802835)}\n",
            "{'Total Return': np.float64(-0.07468723347189277), 'Ann Return': np.float64(-0.008531560459549503), 'Ann Vol': np.float64(0.03729059135168325), 'Sharpe': np.float64(-0.22878587199353703), 'Max Drawdown': -0.17543945227047886, 'Avg Daily Turnover': np.float64(0.0495413081017182), 'Turnover/yr (proxy)': np.float64(12.484409641632986)}\n"
          ]
        }
      ],
      "source": [
        "bt_trend_test = backtest_from_pos_raw_v2(df_test, df_test[\"pos_trend_raw\"])\n",
        "bt_mr_test    = backtest_from_pos_raw_v2(df_test, df_test[\"pos_mr_raw\"])\n",
        "\n",
        "# baseline buy and hold\n",
        "bh_brent = (1 + df_test[\"r\"]).cumprod()\n",
        "print(\"Brent buy and hold return:\", float(bh_brent.iloc[-1] - 1))\n",
        "\n",
        "# for export later\n",
        "df[\"bh_equity\"] = (1 + df_test[\"r\"].fillna(0)).cumprod()\n",
        "\n",
        "print(metrics(bt_trend_test))\n",
        "print(metrics(bt_mr_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwa8gMeXkIps"
      },
      "source": [
        "With this new function we can see that returns are generally better. However, trend 2 is still typically negative (unless we use the magic number of 5 for it's volatility window). Thus, moving forward we should probably just drop it altogether, i.e. there is no edge to be found unlike with the moving average signal. It's probably redundant anyway since we pivoted from mean reversion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqVmcg3tDtph"
      },
      "source": [
        "Let's make a \"portfolio\" by introducing **WTI**, another crude oil."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYDXDksFDykn",
        "outputId": "7c459ecc-6924-4e04-d93c-4d004871b604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Total Return': np.float64(0.07956886572917243), 'Ann Return': np.float64(0.008619482033134451), 'Ann Vol': np.float64(0.10406900608767787), 'Sharpe': np.float64(0.08282467909679621), 'Max Drawdown': -0.2644602891046628, 'Avg Daily Turnover': np.float64(0.08213113976031902), 'Turnover/yr (proxy)': np.float64(20.697047219600393)}\n",
            "wti buy and hold return: 0.06530232558140003\n",
            "wti regime continuation signal: {'Total Return': np.float64(0.20050517917972543), 'Ann Return': np.float64(0.020696628919949944), 'Ann Vol': np.float64(0.08020318896715664), 'Sharpe': np.float64(0.2580524438800713), 'Max Drawdown': -0.2127049285765943, 'Avg Daily Turnover': np.float64(0.10276179456831026), 'Turnover/yr (proxy)': np.float64(25.895972231214188)}\n"
          ]
        }
      ],
      "source": [
        "# clean\n",
        "df_wti = pd.read_csv(\"wti-daily.csv\")\n",
        "df_wti[\"Date\"] = pd.to_datetime(df_wti[\"Date\"])\n",
        "df_wti = df_wti[df_wti[\"Date\"] >= \"2005-01-01\"]\n",
        "df_wti = df_wti.sort_values(\"Date\").drop_duplicates(\"Date\")\n",
        "df_wti = df_wti[df_wti[\"Price\"].notna() & (df_wti[\"Price\"] > 0)]\n",
        "df_wti[\"r\"] = df_wti[\"Price\"].pct_change()\n",
        "df_wti = df_wti.set_index(\"Date\")\n",
        "df_wti[\"r\"] = df_wti[\"r\"].fillna(0)\n",
        "\n",
        "# signal 1\n",
        "# choose delta\n",
        "best_ma_wti, delta_table_wti = choose_deadband_delta(\n",
        "    df_wti,\n",
        "    train_start=train_start,\n",
        "    train_end=train_end,\n",
        ")\n",
        "delta_ma_wti = best_ma_wti[\"delta\"] if best_ma_wti[\"delta\"] is not None else 0.005\n",
        "#print(\"wti delta chosen:\", best_ma_wti)\n",
        "\n",
        "# test\n",
        "df_test_wti = df_wti.loc[\"2017-01-01\":\"2025-12-31\"].copy()\n",
        "\n",
        "# positions\n",
        "df_test_wti[\"pos_trend_raw\"] = make_trend_positions(df_test_wti, ma_window=50, delta=delta_ma_wti)\n",
        "\n",
        "# backtest\n",
        "bt_trend_test_wti = backtest_from_pos_raw_v2(df_test_wti, df_test_wti[\"pos_trend_raw\"])\n",
        "print(metrics(bt_trend_test_wti))\n",
        "\n",
        "# baseline buy and hold\n",
        "bh_wti = (1 + df_test_wti[\"r\"]).cumprod()\n",
        "df_test_wti[\"bh_equity\"] = (1 + df_test_wti[\"r\"].fillna(0)).cumprod()\n",
        "print(\"wti buy and hold return:\", float(bh_wti.iloc[-1] - 1))\n",
        "\n",
        "# signal 2, regime continuation (mean reversion inverted)\n",
        "best_mr_wti, mr_table_wti = choose_mr_threshold(\n",
        "    df_wti,\n",
        "    train_start=train_start,\n",
        "    train_end=train_end,\n",
        ")\n",
        "delta_mr_wti = best_mr_wti[\"a\"] if best_mr_wti[\"a\"] is not None else 1.0\n",
        "df_test_wti[\"pos_mr_raw\"] = make_mr_positions(df_test_wti, z_window=20, a=delta_mr_wti)\n",
        "bt_rc_test_wti = backtest_from_pos_raw_v2(df_test_wti, df_test_wti[\"pos_mr_raw\"])\n",
        "print(\"wti regime continuation signal:\", metrics(bt_rc_test_wti))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnXbtPZXKSA3"
      },
      "source": [
        "**Firstly** I think its interesting to note that with wti, the \"useful\" strategy changes. I.e. we can see that the inverted mr function acts as a better signal than the moving average.\n",
        "\n",
        "Thus I think it would be wise to run seperate strategies depending on stock. So a MA signal for Brent, and a regime continuation signal for WTI.\n",
        "\n",
        "Now let's combine the two commodities into a portfolio. We'll use even weights as since we're not insider trading (lol) I don't see why we would favor one over the other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mjTg5NMJb2t",
        "outputId": "cf2a8fe4-e567-4e00-c809-94cff06d9abf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Portfolio total return: 0.35793898125485923\n",
            "corr: 0.4643803976967573\n"
          ]
        }
      ],
      "source": [
        "# combine for portfolio\n",
        "commodities = pd.DataFrame({\n",
        "    \"brent\": bt_trend_test[\"strat_r\"],\n",
        "    \"wti\": bt_rc_test_wti[\"strat_r\"],\n",
        "}).dropna()\n",
        "\n",
        "commodities[\"port\"] = 0.5*commodities[\"brent\"] + 0.5*commodities[\"wti\"]\n",
        "commodities[\"port_equity\"] = (1 + commodities[\"port\"]).cumprod()\n",
        "print(\"Portfolio total return:\", commodities[\"port_equity\"].iloc[-1] - 1)\n",
        "print(\"corr:\", commodities[\"brent\"].corr(commodities[\"wti\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaRCfzs9NRey"
      },
      "source": [
        "We can see that the correlation is not that high (46%) and so we can try to pick better weights. Let's first compare metrics for each backtest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01wVd5MjNeuv",
        "outputId": "1055b457-5dec-4199-a023-de128a77dd53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Brent: {'Total Return': np.float64(0.6661979730065155), 'Ann Return': np.float64(0.057972602421368036), 'Ann Vol': np.float64(0.1011760232894703), 'Sharpe': np.float64(0.5729875570964591), 'Max Drawdown': -0.20683890286106366, 'Avg Daily Turnover': np.float64(0.07450687721350331), 'Turnover/yr (proxy)': np.float64(18.775733057802835)}\n",
            "Wti: {'Total Return': np.float64(0.20050517917972543), 'Ann Return': np.float64(0.020696628919949944), 'Ann Vol': np.float64(0.08020318896715664), 'Sharpe': np.float64(0.2580524438800713), 'Max Drawdown': -0.2127049285765943, 'Avg Daily Turnover': np.float64(0.10276179456831026), 'Turnover/yr (proxy)': np.float64(25.895972231214188)}\n",
            "Portfolio: {'Total Return': np.float64(0.35793898125485923), 'Ann Return': np.float64(0.0353903563564808), 'Ann Vol': np.float64(0.07795974212276048), 'Sharpe': np.float64(0.4539568165932725), 'Max Drawdown': -0.21607982651294466, 'Avg Daily Turnover': np.float64(0.0), 'Turnover/yr (proxy)': np.float64(0.0)}\n"
          ]
        }
      ],
      "source": [
        "# portfolio backtest\n",
        "\n",
        "# drawdown\n",
        "roll_max = commodities[\"port_equity\"].cummax()\n",
        "commodities[\"port_drawdown\"] = commodities[\"port_equity\"] / roll_max - 1\n",
        "\n",
        "bt_portfolio = pd.DataFrame(index=commodities.index)\n",
        "bt_portfolio[\"strat_r\"] = commodities[\"port\"]\n",
        "bt_portfolio[\"equity\"]  = commodities[\"port_equity\"]\n",
        "# dummy\n",
        "bt_portfolio[\"turnover\"] = 0.0\n",
        "\n",
        "print(\"Brent:\", metrics(bt_trend_test))\n",
        "print(\"Wti:\", metrics(bt_rc_test_wti))\n",
        "print(\"Portfolio:\", metrics(bt_portfolio))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44PPjk_4PurC"
      },
      "source": [
        "We can see slightly less volatility (Ann Vol) on the WTI stock, so if our goal is to **minimize risk by increasing diversification** we can use an inverse volatility weighting system.\n",
        "\n",
        "\\\n",
        "**Something like**:\n",
        "\n",
        "\n",
        "$$\n",
        "\\tilde{w}_B = \\frac{1}{\\sigma_B}, \\qquad \\tilde{w}_W = \\frac{1}{\\sigma_W}\n",
        "$$\n",
        "\n",
        "Where\n",
        "$$\n",
        "w_B = \\frac{\\tilde{w}_B}{\\tilde{w}_B + \\tilde{w}_W}\n",
        "$$\n",
        "\n",
        "$$\n",
        "w_W = 1 - w_B\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjtVJONGYNaY",
        "outputId": "b4eb6c39-30e1-406e-c5a5-4be7e92cafd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weights: 0.4419195342543593 0.5580804657456406\n"
          ]
        }
      ],
      "source": [
        "sigB = commodities[\"brent\"].std()\n",
        "sigW = commodities[\"wti\"].std()\n",
        "\n",
        "wB = (1/sigB) / ((1/sigB) + (1/sigW))\n",
        "wW = 1 - wB\n",
        "\n",
        "print(\"weights:\", wB, wW)\n",
        "\n",
        "commodities[\"port\"] = wB*commodities[\"brent\"] + wW*commodities[\"wti\"]\n",
        "commodities[\"port_equity\"] = (1 + commodities[\"port\"]).cumprod()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbSR1umiYrnZ"
      },
      "source": [
        "Probably not optimized for performance (e.g. returns), but our goal *was* diversification so let's keep the 0.44-0.56 split as its atleast not arbitrary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUGUXrxWlJnt"
      },
      "source": [
        "Okay, Let's make some visualizations in Tableau. We'll need to create a table to export with relevant details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PTrSmJH9nA9G"
      },
      "outputs": [],
      "source": [
        "export = pd.DataFrame(index=commodities.index)\n",
        "# prices\n",
        "export[\"brent_price\"] = df_test[\"Price\"]\n",
        "export[\"wti_price\"]   = df_test_wti[\"Price\"]\n",
        "\n",
        "# backtest returns\n",
        "export[\"brent_strat_r\"] = bt_trend_test[\"strat_r\"]\n",
        "export[\"wti_strat_r\"]   = bt_rc_test_wti[\"strat_r\"]\n",
        "export[\"port_strat_r\"]  = commodities[\"port\"]\n",
        "\n",
        "# equity curves\n",
        "export[\"brent_equity\"] = bt_trend_test[\"equity\"]\n",
        "export[\"wti_equity\"]   = bt_rc_test_wti[\"equity\"]\n",
        "export[\"port_equity\"]  = commodities[\"port_equity\"]\n",
        "\n",
        "# positions\n",
        "export[\"brent_pos\"] = bt_trend_test.get(\"pos_scaled\", bt_trend_test.get(\"pos\"))\n",
        "export[\"wti_pos\"]   = bt_rc_test_wti.get(\"pos_scaled\", bt_rc_test_wti.get(\"pos\"))\n",
        "\n",
        "export[\"brent_scale\"] = bt_trend_test.get(\"scale\")\n",
        "export[\"wti_scale\"]   = bt_rc_test_wti.get(\"scale\")\n",
        "\n",
        "# clean + save\n",
        "export = export.reset_index().rename(columns={\"index\": \"Date\"})\n",
        "export.to_csv(\"commodities_tableau.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
